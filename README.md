# Basic-Neural-Network
This project aims to demonstrate the fundamentals of backpropagation using a simple neural network. We will train a network with an input layer, a hidden layer, and an output layer to identify handwritten digits from the MNIST dataset.

The core focus will be on dissecting the mathematical principles behind gradient descent and backpropagation within this basic neural network architecture.
